{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a python program which searches all the product under a particular product vertical from www.amazon.in. The product verticals to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchjob=driver.find_element_by_id('twotabsearchtextbox')\n",
    "searchjob.send_keys(input('enter the value:'))\n",
    "searchbtn=driver.find_element_by_xpath(\"//input[@id='nav-search-submit-button']\")\n",
    "searchbtn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product vertical has  less than 3 pages in search results then scrape all the products available under that product vertical. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of Ratings\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/s?k=Laptop&crid=159Z09A0DWEJ2&sprefix=laptop%2Caps%2C433&ref=nb_sb_noss_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):\n",
    "    urls.append(i.get_attribute('href'))\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "name=[]\n",
    "rating=[]\n",
    "noofratings=[]\n",
    "price=[]\n",
    "exchange=[]\n",
    "delivery=[]\n",
    "availability=[]\n",
    "details=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        b=driver.find_element_by_xpath(\"//tr[2][@class='a-spacing-small']/td[2]/span[1]\")\n",
    "        brand.append(b.text)\n",
    "    except:\n",
    "        brand.append('-')\n",
    "    try:\n",
    "        n=driver.find_element_by_xpath(\"//span[@class='a-size-large product-title-word-break']\")\n",
    "        name.append(n.text)\n",
    "    except:\n",
    "        name.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        rat=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        rating.append(rat.text)\n",
    "    except:\n",
    "        rating.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        no=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-medium averageStarRatingNumerical']/span\")\n",
    "        noofratings.append(no.text)\n",
    "    except:\n",
    "        noofratings.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        p=driver.find_element_by_xpath(\"//td[@class='a-span12']/span[1]\")\n",
    "        price.append(p.text)\n",
    "    except:\n",
    "        price.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        ex=driver.find_element_by_xpath(\"//div[@class='a-row icon-farm-wrapper']/div[1]/span[1]/div[2]/a\")\n",
    "        exchange.append(ex.text)\n",
    "    except:\n",
    "        exchange.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        de=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-mini']/b\")\n",
    "        delivery.append(de.text)\n",
    "    except:\n",
    "        delivery.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        av=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base }']/span[1]\")\n",
    "        availability.append(av.text)\n",
    "    except:\n",
    "        availability.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        d=driver.find_element_by_xpath(\"//ul[@class='a-unordered-list a-vertical a-spacing-mini']\")\n",
    "        details.append(d.text)\n",
    "    except:\n",
    "        details.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(brand))\n",
    "print(len(name))\n",
    "print(len(price))\n",
    "print(len(rating))\n",
    "print(len(noofratings))\n",
    "print(len(exchange))\n",
    "print(len(delivery))\n",
    "print(len(availability))\n",
    "print(len(details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop=pd.DataFrame({})\n",
    "laptop['brand']=brand[0:10]\n",
    "laptop['name']=name[0:10]\n",
    "laptop['rating']=rating[0:10]\n",
    "laptop['noofratings']=noofratings[0:10]\n",
    "laptop['price']=price[0:10]\n",
    "laptop['exchange']=exchange[0:10]\n",
    "laptop['delivery']=delivery[0:10]\n",
    "laptop['availability']=availability[0:10]\n",
    "laptop['details']=details[0:10]\n",
    "laptop['url']=urls[0:10]\n",
    "laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop.to_csv('laptops.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Write a python program to access the search bar and search button on images.google.com and scrape 100 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\")\n",
    "box.send_keys('fruits')\n",
    "box.send_keys(Keys.ENTER)\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='MUFPAc']/div[2]/a\").click()\n",
    "\n",
    "\n",
    "#Will keep scrolling down the webpage until it cannot scroll no more\n",
    "last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "    time.sleep(2)\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"islmp\"]/div/div/div/div/div[5]/input').click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "for i in range(1,100):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//*[@id='islrg']/div[1]/div['+str(i)+']/a[1]/div[1]/img\").screenshot('C:\\fruits('+str(i)+').png')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\")\n",
    "box.send_keys('Cars')\n",
    "box.send_keys(Keys.ENTER)\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='MUFPAc']/div[2]/a\").click()\n",
    "\n",
    "\n",
    "#Will keep scrolling down the webpage until it cannot scroll no more\n",
    "last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "    time.sleep(2)\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"islmp\"]/div/div/div/div/div[5]/input').click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "for i in range(1,100):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//*[@id='islrg']/div[1]/div['+str(i)+']/a[1]/div[1]/img\").screenshot('C:\\fruits('+str(i)+').png')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\")\n",
    "box.send_keys('Machine Learning')\n",
    "box.send_keys(Keys.ENTER)\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='MUFPAc']/div[3]/a\").click()\n",
    "\n",
    "\n",
    "#Will keep scrolling down the webpage until it cannot scroll no more\n",
    "last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "    time.sleep(2)\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"islmp\"]/div/div/div/div/div[5]/input').click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "for i in range(1,100):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//*[@id='islrg']/div[1]/div['+str(i)+']/a[1]/div[1]/img\").screenshot('C:\\fruits('+str(i)+').png')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Display Resolution”, “Processor”, “Processor Cores”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelbtn=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "cancelbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input[1]\")\n",
    "search.send_keys('Smartphone')\n",
    "searchbtn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "searchbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/search?q=Smartphone&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_2kHMtA']/a\"):\n",
    "    urls.append(i.get_attribute('href'))\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "name=[]\n",
    "color=[]\n",
    "ram=[]\n",
    "storage=[]\n",
    "primarycamera=[]\n",
    "secondarycamera=[]\n",
    "displaysize=[]\n",
    "displayresolution=[]\n",
    "processor=[]\n",
    "processorcore=[]\n",
    "battery=[]\n",
    "price=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        b=driver.find_element_by_xpath(\"//div[@class='_1MR4o5']/div[4]/a\")\n",
    "        brand.append(b.text)\n",
    "    except:\n",
    "        brand.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        nam=driver.find_element_by_xpath(\"//span[@class='B_NuCI']\")\n",
    "        name.append(nam.text)\n",
    "    except:\n",
    "        name.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        co=driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][1]/table/tbody/tr[4]/td[2]/ul/li\")\n",
    "        color.append(co.text)\n",
    "    except:\n",
    "        color.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        r=driver.find_element_by_xpath(\"//div[@class='_3k-BhJ'][4]/table[1]/tbody/tr[2]/td[2]/ul/li\")\n",
    "        ram.append(r.text)\n",
    "    except NoSuchElementException:\n",
    "        ram.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ram[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.google.com/maps/@28.6719596,77.3668959,15z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchjob=driver.find_element_by_id('searchboxinput')\n",
    "searchjob.send_keys(input('enter the value:'))\n",
    "searchbtn=driver.find_element_by_xpath(\"//div[@class='xoLGzf-BIqFsb-haAclf']/button\")\n",
    "searchbtn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: if you click any location in the maps. it will show you the latitute and longitude of that location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude=[]\n",
    "link=driver.find_elements_by_xpath(\"//div[@class='GaSlwc-uhFGfc-WsjYwc-haAclf']/button[2]\")\n",
    "link[0:10]\n",
    "\n",
    "for i in link:\n",
    "    lat=i.text\n",
    "    latitude.append(lat)\n",
    "latitude[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 –September 20) from trak.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://trak.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "searchbtn=driver.find_element_by_xpath(\"//span[@class='search-handler']/i\")\n",
    "searchbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_xpath(\"//div[@class='search-box clearfix']/form/input\")\n",
    "search.send_keys('funding deals for second quarter')\n",
    "search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://trak.in/?s=funding+deals+for+second+quarter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deals=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=driver.find_elements_by_xpath(\"//h2[@class='title']/a\")\n",
    "d[0:20]\n",
    "for i in d:\n",
    "    de=i.text\n",
    "    deals.append(de)\n",
    "deals[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Write a program to scrap all the available details of best gaming laptops from digit.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.digit.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "searchbtn=driver.find_element_by_xpath(\"//div[@class='menu']/ul/li[3]\")\n",
    "searchbtn.click()\n",
    "time.sleep(3)\n",
    "searchbtn=driver.find_element_by_xpath(\"//div[@class='Listbrand']/ul/li[10]\")\n",
    "searchbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.digit.in/top-products/best-gaming-laptops-40.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "os=[]\n",
    "display=[]\n",
    "processor=[]\n",
    "memory=[]\n",
    "weight=[]\n",
    "dimension=[]\n",
    "graphics=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=driver.find_elements_by_xpath(\"//div[@class='right-container']/div/a/h3\")\n",
    "a[0:10]\n",
    "\n",
    "for i in a :\n",
    "    na=i.text\n",
    "    name.append(na)\n",
    "name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr[3]/td[3]\")\n",
    "b[0:10]\n",
    "\n",
    "for i in b :\n",
    "    operating=i.text\n",
    "    os.append(operating)\n",
    "os[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr[4]/td[3]\")\n",
    "c[0:10]\n",
    "\n",
    "for i in c :\n",
    "    dis=i.text\n",
    "    display.append(dis)\n",
    "display[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr[5]/td[3]\")\n",
    "d[0:10]\n",
    "\n",
    "for i in d :\n",
    "    pros=i.text\n",
    "    processor.append(pros)\n",
    "processor[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr[6]/td[3]\")\n",
    "e[0:10]\n",
    "\n",
    "for i in e :\n",
    "    mem=i.text\n",
    "    memory.append(mem)\n",
    "memory[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr[7]/td[3]\")\n",
    "f[0:10]\n",
    "\n",
    "for i in f :\n",
    "    wei=i.text\n",
    "    weight.append(wei)\n",
    "weight[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr[8]/td[3]\")\n",
    "g[0:10]\n",
    "\n",
    "for i in g :\n",
    "    dim=i.text\n",
    "    dimension.append(dim)\n",
    "dimension[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=driver.find_elements_by_xpath(\"//div[@class='Spcs-details']/table/tbody/tr[9]/td[3]\")\n",
    "j[0:10]\n",
    "\n",
    "for i in j :\n",
    "    gra=i.text\n",
    "    graphics.append(gra)\n",
    "graphics[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=driver.find_elements_by_xpath(\"//table[@class='table']/tbody/tr/td[3]/strong\")\n",
    "h[0:10]\n",
    "\n",
    "for i in h :\n",
    "    pr=i.text\n",
    "    price.append(pr)\n",
    "price[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops=pd.DataFrame({})\n",
    "laptops['name']=name[0:10]\n",
    "laptops['os']=os[0:10]\n",
    "laptops['display']=display[0:10]\n",
    "laptops['processor']=processor[0:10]\n",
    "laptops['memory']=memory[0:10]\n",
    "laptops['weight']=weight[0:10]\n",
    "laptops['dimension']=dimension[0:10]\n",
    "laptops['graphics']=graphics[0:10]\n",
    "laptops['price']=price[0:10]\n",
    "laptops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.forbes.com/forbes-400/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "networth=[]\n",
    "age=[]\n",
    "citizenship=[]\n",
    "source=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=driver.find_elements_by_xpath(\"//div[@class='rank']/div\")\n",
    "a[0:200]\n",
    "\n",
    "for i in a :\n",
    "    ra=i.text\n",
    "    rank.append(na)\n",
    "rank[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=driver.find_elements_by_xpath(\"//div[@class='personName']\")\n",
    "b[0:200]\n",
    "\n",
    "for i in b:\n",
    "    na=i.text\n",
    "    name.append(na)\n",
    "name[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=driver.find_elements_by_xpath(\"//div[@class='netWorth']\")\n",
    "c[0:200]\n",
    "\n",
    "for i in c :\n",
    "    nw=i.text\n",
    "    networth.append(nw)\n",
    "networth[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=driver.find_elements_by_xpath(\"//div[@class='age']\")\n",
    "d[0:200]\n",
    "\n",
    "for i in d :\n",
    "    ag=i.text\n",
    "    age.append(ag)\n",
    "age[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=driver.find_elements_by_xpath(\"//div[@class='state']\")\n",
    "e[0:200]\n",
    "\n",
    "for i in e :\n",
    "    cit=i.text\n",
    "    citizenship.append(cit)\n",
    "citizenship[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=driver.find_elements_by_xpath(\"//div[@class='source']\")\n",
    "f[0:200]\n",
    "\n",
    "for i in f :\n",
    "    sou=i.text\n",
    "    source.append(sou)\n",
    "source[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich=pd.DataFrame({})\n",
    "rich['rank']=rank[0:200]\n",
    "rich['name']=name[0:200]\n",
    "rich['networth']=networth[0:200]\n",
    "rich['age']=age[0:200]\n",
    "rich['citizenship']=citizenship[0:200]\n",
    "rich['source']=source[0:200]\n",
    "rich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.youtube.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchbtn=driver.find_element_by_xpath(\"//ytd-rich-item-renderer[@class='style-scope ytd-rich-grid-renderer'][20]\")\n",
    "searchbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.youtube.com/watch?v=Dp6lbdoprZ0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments=[]\n",
    "vote=[]\n",
    "time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=driver.find_elements_by_xpath(\"//ytd-expander[@class='style-scope ytd-comment-renderer']\")\n",
    "a[0:500]\n",
    "\n",
    "for i in a :\n",
    "    com=i.text\n",
    "    comments.append(com)\n",
    "comments[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=driver.find_elements_by_xpath(\"//ytd-comment-action-buttons-renderer[@class='style-scope ytd-comment-renderer']/div[1]/span[2]\")\n",
    "b[0:500]\n",
    "\n",
    "for i in b :\n",
    "    vo=i.text\n",
    "    vote.append(vo)\n",
    "vote[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=driver.find_elements_by_xpath(\"//div[@id='header-author']/yt-formatted-string/a\")\n",
    "c[0:500]\n",
    "\n",
    "for i in c :\n",
    "    ti=i.text\n",
    "    time.append(ti)\n",
    "time[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video=pd.DataFrame({})\n",
    "video['comments']=comments[0:500]\n",
    "video['vote']=vote[0:500]\n",
    "video['time']=time[0:500]\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in “London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:/chromedriver.exe')\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.hostelworld.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchbtn=driver.find_element_by_xpath(\"//input[@class='location-text']\")\n",
    "searchbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchjob=driver.find_element_by_xpath(\"//input[@id='search-input-field']\")\n",
    "searchjob.send_keys('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcbtn=driver.find_element_by_xpath(\"//ul[@id='predicted-search-results']/li[2]/div\")\n",
    "searcbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gobtn=driver.find_element_by_xpath(\"//button[@id='search-button']\")\n",
    "gobtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//h2[@class='title title-6']/a\"):\n",
    "    urls.append(i.get_attribute('href'))\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "distances=[]\n",
    "ratingss=[]\n",
    "treviews=[]\n",
    "oreview=[]\n",
    "privatepric=[]\n",
    "dormprice=[]\n",
    "facilities=[]\n",
    "descriptions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        des=driver.find_element_by_xpath(\"//div[@class='flex-80']/div[2]/div/div[2]\")\n",
    "        descriptions.append(des.text)\n",
    "    except:\n",
    "        descriptions.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.hostelworld.com/s?q=London,%20England&country=England&city=London&type=city&id=3&from=2021-10-26&to=2021-10-29&guests=2&page=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name\n",
    "n=driver.find_elements_by_xpath(\"//h2[@class='title title-6']\")\n",
    "n[0:30]\n",
    "for i in n:\n",
    "    na=i.text\n",
    "    name.append(na)\n",
    "name[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distances\n",
    "di=driver.find_elements_by_xpath(\"//a[@class='show-on-map']/span[1]\")\n",
    "di[0:30]\n",
    "for i in di:\n",
    "    dis=i.text\n",
    "    distances.append(dis)\n",
    "distances[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratingss\n",
    "raa=driver.find_elements_by_xpath(\"//div[@class='rating rating-summary-container big']/div[1]\")\n",
    "raa[0:30]\n",
    "for i in raa:\n",
    "    raat=i.text\n",
    "    ratingss.append(raat)\n",
    "ratingss[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treviews\n",
    "tr=driver.find_elements_by_xpath(\"//div[@class='rating rating-summary-container big']/div[2]/div[2]\")\n",
    "tr[0:30]\n",
    "for i in tr:\n",
    "    tri=i.text\n",
    "    treviews.append(tri)\n",
    "treviews[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oreviews\n",
    "ori=driver.find_elements_by_xpath(\"//div[@class='rating rating-summary-container big']/div[2]/div[1]/span\")\n",
    "ori[0:30]\n",
    "for i in ori:\n",
    "    oriv=i.text\n",
    "    oreview.append(oriv)\n",
    "oreview[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#privateprices\n",
    "prti=driver.find_elements_by_xpath(\"//a[@class='prices']/div[1]/div\")\n",
    "prti[0:30]\n",
    "for i in prti:\n",
    "    prttt=i.text\n",
    "    privatepric.append(prttt)\n",
    "privatepric[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dormprice\n",
    "drti=driver.find_elements_by_xpath(\"//a[@class='prices']/div[2]/div\")\n",
    "drti[0:30]\n",
    "for i in drti:\n",
    "    drttt=i.text\n",
    "    dormprice.append(drttt)\n",
    "dormprice[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#facilities\n",
    "fac=driver.find_elements_by_xpath(\"//div[@class='rating-factors prop-card-tablet rating-factors small']\")\n",
    "fac[0:30]\n",
    "for i in fac:\n",
    "    faci=i.text\n",
    "    facilities.append(faci)\n",
    "facilities[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(descriptions[0:30]))\n",
    "print(len(name[0:30]))\n",
    "print(len(distances[0:30]))\n",
    "print(len(ratingss[0:30]))\n",
    "print(len(treviews[0:30]))\n",
    "print(len(oreview[0:30]))\n",
    "print(len(privatepric[0:30]))\n",
    "print(len(dormprice[0:30]))\n",
    "print(len(facilities[0:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostel=pd.DataFrame({})\n",
    "hostel['name']=name[0:30]\n",
    "hostel['distance']=distances[0:30]\n",
    "hostel['ratings']=ratingss[0:30]\n",
    "hostel['total']=treviews[0:30]\n",
    "hostel['overall']=oreview[0:30]\n",
    "hostel['private']=privatepric[0:30]\n",
    "hostel['dorm']=dormprice[0:30]\n",
    "hostel['facilities']=facilities[0:30]\n",
    "hostel['description']=descriptions[0:30]\n",
    "hostel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
